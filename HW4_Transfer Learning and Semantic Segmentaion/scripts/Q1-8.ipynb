{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Q1-8.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Y2TnpdCDuDnT"},"source":["**Initial step:** Please try to put the extracted heavy_makeup_CelebA folder in your Google Drive!\n","So now you could mount your data to this ipynb!"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"09fk3N3Gn1Pl","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KJihfaYeoG8m","colab":{}},"source":["# if you mount Google drive correctly, the following commands should be able to be executed correctly\n","!ls /content/drive/\n","%cd \"/content/drive/My Drive\"\n","%cd \"heavy_makeup_CelebA\"\n","\n","!ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NCmzcH9siOTH","colab":{}},"source":["from __future__ import print_function, division\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","\n","plt.ion()   # interactive mode"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RTZrF2PdjPcU","colab":{}},"source":["## Please try to adjust data augmentation strategy here\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","# the directory of your data in Google Drive\n","#data_dir = './heavy_makeup_CelebA'\n","data_dir = '/content/drive/My Drive/heavy_makeup_CelebA'\n","\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","\n","class_names = image_datasets['train'].classes\n","\n","#print(torch.cuda.is_available())\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"69P-kXNr46dQ"},"source":["Let's show some training data. Make sure the lables match the images"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QxL65Tiole9n","colab":{}},"source":["def imshow(inp, title=None):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","\n","\n","# Get a batch of training data\n","inputs, classes = next(iter(dataloaders['train']))\n","\n","# Make a grid from batch\n","out = torchvision.utils.make_grid(inputs)\n","\n","imshow(out, title=[class_names[x] for x in classes])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pJkOaVv9lwJa"},"source":["Training the model\n","Now, letâ€™s write a general function to train a model. Here, we will illustrate:\n","\n","Scheduling the learning rate\n","Saving the best model\n","In the following, parameter scheduler is an LR scheduler object from torch.optim.lr_scheduler."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Z6RZDPY6lxoS","colab":{}},"source":["def train_model(model, criterion, optimizer, scheduler, dataloader,num_epochs=25):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloader[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)                            \n","                running_corrects += torch.sum(preds == labels.data)\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nQt3IXA0_cRT"},"source":["**Case 1:**\n","using ConvNet as fixed feature extractor\n","Here, we need to freeze all the network except the final layer. We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward().\n","\n","You can read more about this in the documentation here."]},{"cell_type":"code","metadata":{"id":"vRpQNPdWQCzQ","colab_type":"code","colab":{}},"source":["model_resnet = models.alexnet(pretrained=True)\n","print(model_resnet)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WkcOdA4o_gzh","colab":{}},"source":["model_conv = models.alexnet(pretrained=True)\n","for param in model_conv.parameters():\n","    param.requires_grad = False\n","\n","# Parameters of newly constructed modules have requires_grad=True by default\n","model_conv.classifier = nn.Sequential(*[model_conv.classifier[i] for i in range(6)]) # remove the last layer (4096x1000)\n","addition_fc = nn.Linear(4096, 2) # the layer to be stacked\n","model_conv.classifier = nn.Sequential(model_conv.classifier,addition_fc)\n","\n","model_conv = model_conv.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","# Observe that only parameters of final layer are being optimized as\n","# opposed to before.\n","optimizer_conv = optim.SGD(model_conv.parameters(), lr=0.001, momentum=0.9)\n","\n","# Decay LR by a factor of 0.1 every 7 epochs\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=5, gamma=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ASUNHxIrVQjX"},"source":["Let's train the model as a feature extractor"]},{"cell_type":"code","metadata":{"id":"duNt91UDQCzj","colab_type":"code","colab":{}},"source":["#print(model_conv)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IpNyOhSM_llg","colab":{}},"source":["#model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=25)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TQSHmLcdmgpf"},"source":["**Case 2**: Finetuning the convnet\n","Load a pretrained model and reset final fully connected layer."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4TwcHLSKmi03","colab":{}},"source":["## Alexnet\n","model_ft = models.alexnet(pretrained=True)\n","model_ft.classifier = nn.Sequential(*[model_ft.classifier[i] for i in range(6)])  # remove the last layer (4096x1000)\n","addition_fc = nn.Linear(4096, 2) # the layer to be stacked\n","model_ft.classifier = nn.Sequential(model_ft.classifier,addition_fc)\n","#model_ft = nn.Sequential(model_ft,addition_fc)\n","print(model_ft)\n","##\n","\n","model_ft = model_ft.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","# Observe that all parameters are being optimized\n","optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n","\n","# step size could be\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dI6yUHZrmqtd"},"source":["Train and evaluate\n","It should take around 15-25 min on CPU. On GPU though, it takes less than 5 minutes."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Tp07ugkXms8l","colab":{}},"source":["#model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_OU2kGYPmUGz"},"source":["**Visualizing the model predictions:**\n","Generic function to display predictions for a few images"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"G3u5SQux51pH","colab":{}},"source":["def visualize_model(model, num_images=6):\n","    was_training = model.training\n","    model.eval()\n","    images_so_far = 0\n","    fig = plt.figure()\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(dataloaders['train']):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","\n","            for j in range(inputs.size()[0]):\n","                images_so_far += 1\n","                ax = plt.subplot(num_images//2, 2, images_so_far)\n","                ax.axis('off')\n","                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n","                imshow(inputs.cpu().data[j])\n","\n","                if images_so_far == num_images:\n","                    model.train(mode=was_training)\n","                    return\n","        model.train(mode=was_training)\n","        \n","#model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)\n","#visualize_model(model_ft)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UMDmvuiRQC0S","colab_type":"text"},"source":["#### Visualize the photo under augmentation strategy "]},{"cell_type":"code","metadata":{"id":"Gb87oARTQC0V","colab_type":"code","colab":{}},"source":["def visualize_photo(dataloaders, num_images=6):\n","    images_so_far = 0\n","    fig = plt.figure()\n","    for i, (inputs, labels) in enumerate(dataloaders['train']):\n","        inputs = inputs\n","        labels = labels\n","        for j in range(inputs.size()[0]):\n","            images_so_far += 1\n","            ax = plt.subplot(num_images//2, 2, images_so_far)\n","            ax.axis('off')\n","            ax.set_title('gnd: {}'.format(class_names[labels[j]]))\n","            imshow(inputs.data[j])\n","\n","            if images_so_far == num_images:\n","                return\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"80o9NdBVQC0f","colab_type":"text"},"source":["#### (1)visualize the original strategy"]},{"cell_type":"code","metadata":{"id":"FscCcd8jQC0j","colab_type":"code","colab":{}},"source":["visualize_photo(dataloaders)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-4w83kgZQC0t","colab_type":"text"},"source":["#### (2)visualize my strategy"]},{"cell_type":"code","metadata":{"id":"U_FVha84QC0x","colab_type":"code","colab":{}},"source":["data_transforms_2 = {\n","    'train': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.ColorJitter(contrast=0.25,brightness =0.25),\n","        transforms.RandomRotation(degrees =15),\n","       # transforms.RandomOrder[\n","        #transforms.RandomResizedCrop(224),\n","        transforms.CenterCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        #],\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1nnOl6p1QC07","colab_type":"code","colab":{}},"source":["image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms_2[x]) for x in ['train', 'val']}\n","dataloaders_2 = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","\n","class_names = image_datasets['train'].classes\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VAGPJSKgQC1M","colab_type":"text"},"source":["- check the dataloader under new transformer,data_transform_2"]},{"cell_type":"code","metadata":{"id":"mY1_ZwsaQC1P","colab_type":"code","colab":{}},"source":["visualize_photo(dataloaders_2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cr_pArsiQC1a","colab_type":"text"},"source":["### Q1-8. Please try to achieve validation accuracy higher than 89.5% using a CNN other than Alexnet& ResNet-18 in the fine-tuning case. (20pts)"]},{"cell_type":"code","metadata":{"id":"CzHTKwQcQC1d","colab_type":"code","colab":{}},"source":["#model_9 = torch.hub.load('pytorch/vision:v0.4.2', 'shufflenet_v2_x1_0', pretrained=True)\n","model_9 = torch.hub.load('pytorch/vision:v0.4.2', 'mobilenet_v2', pretrained=True)\n","\n","model_9.classifier = nn.Sequential(*list(model_9.classifier.children())[:-1]) # remove the last layer (4096x1000)\n","addition_fc = nn.Linear(1280, 2) # the layer to be stacked\n","model_9.classifier=nn.Sequential(model_9.classifier,addition_fc)\n","\n","model_9 = model_9.to(device)\n","print(model_9)\n","optimizer_9 = optim.Adam(model_9.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","#optimizer_9 = optim.SGD(model_9.parameters(), lr=0.001, momentum=0.9)\n","\n","# step size could be\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_9, step_size=5, gamma=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kNKn7VHwQC1l","colab_type":"code","colab":{}},"source":["model_9 = train_model(model_9, criterion, optimizer_9, exp_lr_scheduler,dataloader = dataloaders_2, num_epochs=25)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tU-CANIFQC1s","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}