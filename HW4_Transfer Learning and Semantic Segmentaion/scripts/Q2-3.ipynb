{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Q2-3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6MlHCEAdZPy1"
      },
      "source": [
        "**Initial step:** Please try to put the extracted CamVid folder in your Google Drive!\n",
        "So now you could mount your data to this ipynb!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UGAXY5HMYjzL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "472da49d-bb13-4bf0-8cab-693715d1c101"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wTBYCMcpZoA8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "bb41625a-4000-4192-b486-24863a39614b"
      },
      "source": [
        "# if you mount Google drive correctly, the following commands should be able to executed correctly\n",
        "!ls /content/drive/\n",
        "%cd \"/content/drive/My Drive\"\n",
        "%cd \"CamVid\"\n",
        "\n",
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'My Drive'  'Shared drives'\n",
            "/content/drive/My Drive\n",
            "/content/drive/My Drive/CamVid\n",
            "result_comparision  train  trainannot  train.csv  val  valannot  val.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pfWmPZKyZ8gA",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import utils\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torchvision.models.vgg import VGG\n",
        "import random\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "from os import path\n",
        "\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torchvision.models.vgg import VGG\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chkDR-wIb7ba",
        "colab_type": "text"
      },
      "source": [
        "### Q2-3. Please try to further reduce the number of classes from 11 to 3 and report the pixel accuracy & mIOUof FCN8s. (10 pts)\n",
        "ps. Please don’t create another copy of dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YMzL2KhcaI9u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c3941e21-69e8-461d-fe51-fbec4cfcf286"
      },
      "source": [
        "#root_dir = './CamVid/'\n",
        "root_dir   = \"/content/drive/My Drive/CamVid/\"\n",
        "train_file = os.path.join(root_dir, \"train.csv\")\n",
        "val_file   = os.path.join(root_dir, \"val.csv\")\n",
        "\n",
        "print(\"training csv exits:{}\".format(path.exists(train_file)))\n",
        "print(\"validation csv exits:{}\".format(path.exists(val_file)))\n",
        "\n",
        "# the folder to save results for comparison\n",
        "folder_to_save_validation_result = root_dir + '/result_comparision/' \n",
        "\n",
        "if os.path.isdir(folder_to_save_validation_result) == False:\n",
        "    os.mkdir(folder_to_save_validation_result)\n",
        "\n",
        "\n",
        "# the number of segmentation classes\n",
        "num_class = 3 # 32 for original CamVid <--- change the class number here\n",
        "means     = np.array([103.939, 116.779, 123.68]) / 255. # mean of three channels in the order of BGR\n",
        "\n",
        "h, w      = 256, 256\n",
        "train_h = 256\n",
        "train_w = 256\n",
        "val_h = 256\n",
        "val_w = 256\n",
        "\n",
        "## parameters for Solver-Adam in this example\n",
        "batch_size = 6 #\n",
        "epochs     = 20 # don't try to improve the performance by simply increasing the training epochs or iterations\n",
        "lr         = 1e-4    # achieved besty results \n",
        "step_size  = 100 # Won't work when epochs <=100\n",
        "gamma      = 0.5 # \n",
        "#\n",
        "\n",
        "## index for validation images\n",
        "global_index = 0\n",
        "\n",
        "# pixel accuracy and mIOU list \n",
        "pixel_acc_list = []\n",
        "mIOU_list = []\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "num_gpu = list(range(torch.cuda.device_count()))\n",
        "\n",
        "class CamVidDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file, phase, n_class=num_class, crop=True, flip_rate=0.5):\n",
        "        self.data      = pd.read_csv(csv_file)\n",
        "        self.means     = means\n",
        "        self.n_class   = n_class\n",
        "        self.flip_rate = flip_rate       \n",
        "\n",
        "        self.resize_h = h\n",
        "        self.resize_w = w        \n",
        "        \n",
        "        if phase == 'train':\n",
        "            self.new_h = train_h\n",
        "            self.new_w = train_w\n",
        "            self.crop = crop\n",
        "        elif phase == 'val':\n",
        "            self.flip_rate = 0.\n",
        "            self.crop = False # False\n",
        "            self.new_h = val_h\n",
        "            self.new_w = val_w\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name   = self.data.iloc[idx, 0]                \n",
        "        img_name = root_dir  + img_name                        \n",
        "        img = Image.open(img_name).convert('RGB')  \n",
        "\n",
        "        label_name = self.data.iloc[idx, 1]        \n",
        "        label_name = root_dir  + label_name                       \n",
        "        label_image = Image.open(label_name)\n",
        "        label = np.asarray(label_image)\n",
        "\n",
        "        # In training mode, the crop strategy is random-shift crop.\n",
        "        # In validation model, it is center crop.\n",
        "        if self.crop:            \n",
        "            w, h = img.size\n",
        "            A_x_offset = np.int32(np.random.randint(0, w - self.new_w + 1, 1))[0]\n",
        "            A_y_offset = np.int32(np.random.randint(0, h - self.new_h + 1, 1))[0]\n",
        "\n",
        "            img = img.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n",
        "            label_image = label_image.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n",
        "        else:            \n",
        "            w, h = img.size\n",
        "            A_x_offset = int((w - self.new_w)/2)\n",
        "            A_y_offset = int((h - self.new_h)/2)\n",
        "            \n",
        "            img = img.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n",
        "            label_image = label_image.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n",
        "\n",
        "            label_image_h, label_image_w = label_image.size\n",
        "\n",
        "        # we could try to revise the values in label for reducing the number of segmentation classes\n",
        "        label = np.array(label_image)              \n",
        "\n",
        "        if random.random() < self.flip_rate:\n",
        "            img   = np.fliplr(img)\n",
        "            label = np.fliplr(label)\n",
        "        \n",
        "        # reduce mean in terms of BGR\n",
        "        img = np.transpose(img, (2, 0, 1)) / 255.\n",
        "        img[0] -= self.means[0]\n",
        "        img[1] -= self.means[1]\n",
        "        img[2] -= self.means[2]\n",
        "\n",
        "        # convert to tensor\n",
        "        img = torch.from_numpy(img.copy()).float()\n",
        "        label = torch.from_numpy(label.copy()).long()\n",
        "\n",
        "        # create one-hot encoding  ???????\n",
        "        h, w = label.size()\n",
        "        target = torch.zeros(self.n_class, h, w)\n",
        "        for c in range(self.n_class):\n",
        "            target[c][label == c] = 1\n",
        "\n",
        "        sample = {'X': img, 'Y': target, 'l': label}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "train_data = CamVidDataset(csv_file=train_file, phase='train')\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "val_data = CamVidDataset(csv_file=val_file, phase='val', flip_rate=0)\n",
        "val_loader = DataLoader(val_data, batch_size=1, num_workers=0)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training csv exits:True\n",
            "validation csv exits:True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4h-a5moWhLhF",
        "outputId": "9b143162-197d-469a-f72a-21ab1a82d7ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# cropped version from https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\n",
        "cfg = {\n",
        "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "ranges = {\n",
        "    'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n",
        "    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n",
        "    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n",
        "    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n",
        "}\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class VGGNet(VGG):\n",
        "    def __init__(self, pretrained=True, model='vgg16', requires_grad=True, remove_fc=True, show_params=False):\n",
        "        super().__init__(make_layers(cfg[model]))\n",
        "        self.ranges = ranges[model]\n",
        "\n",
        "        if pretrained:            \n",
        "            exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n",
        "\n",
        "        if not requires_grad:\n",
        "            for param in super().parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        if remove_fc:  # delete redundant fully-connected layer params, can save memory\n",
        "            del self.classifier\n",
        "\n",
        "        if show_params:\n",
        "            for name, param in self.named_parameters():\n",
        "                print(name, param.size())\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = {}\n",
        "\n",
        "        # get the output of each maxpooling layer (5 maxpool in VGG net)\n",
        "        for idx in range(len(self.ranges)):\n",
        "            for layer in range(self.ranges[idx][0], self.ranges[idx][1]):\n",
        "                x = self.features[layer](x)\n",
        "            output[\"x%d\"%(idx+1)] = x\n",
        "\n",
        "        return output\n",
        "\n",
        "class FCN8s(nn.Module):\n",
        "    #Ref: https://towardsdatascience.com/review-fcn-semantic-segmentation-eb8c9b50d2d1\n",
        "    #The layer description is accordance with the above fiture instead of the original paper. Alex 2019/12/03 \n",
        "    def __init__(self, pretrained_net, n_class):\n",
        "        super().__init__()\n",
        "        self.n_class = n_class\n",
        "        self.pretrained_net = pretrained_net\n",
        "        self.relu    = nn.ReLU(inplace=True)\n",
        "        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn1     = nn.BatchNorm2d(512)\n",
        "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn2     = nn.BatchNorm2d(256)\n",
        "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn3     = nn.BatchNorm2d(128)\n",
        "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn4     = nn.BatchNorm2d(64)\n",
        "        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn5     = nn.BatchNorm2d(32)\n",
        "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.pretrained_net(x)\n",
        "        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n",
        "        x4 = output['x4']  # size=(N, 512, x.H/16, x.W/16)\n",
        "        x3 = output['x3']  # size=(N, 256, x.H/8,  x.W/8)\n",
        "\n",
        "        score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n",
        "        score = self.bn1(score + x4)                      # element-wise add, size=(N, 512, x.H/16, x.W/16)                      \n",
        "        score = self.relu(self.deconv2(score))            # size=(N, 256, x.H/8, x.W/8)\n",
        "        score = self.bn2(score + x3)                      # element-wise add, size=(N, 256, x.H/8, x.W/8)           \n",
        "        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n",
        "        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n",
        "        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n",
        "        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n",
        "\n",
        "        return score  # size=(N, n_class, x.H/1, x.W/1)\n",
        "\n",
        "# load pretrained weights and define FCN8s\n",
        "vgg_model = VGGNet(requires_grad=True, remove_fc=True)\n",
        "fcn_model = FCN8s(pretrained_net=vgg_model, n_class=num_class)\n",
        "\n",
        "ts = time.time()\n",
        "vgg_model = vgg_model.cuda()\n",
        "fcn_model = fcn_model.cuda()\n",
        "fcn_model = nn.DataParallel(fcn_model, device_ids=num_gpu)\n",
        "print(\"Finish cuda loading, time elapsed {}\".format(time.time() - ts))\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(fcn_model.parameters(), lr=lr)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)  "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:46<00:00, 12.0MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finish cuda loading, time elapsed 9.216722965240479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64XJOyD_b7bi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(fcn_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lUjPeffKbm36",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    for epoch in range(epochs):\n",
        "        scheduler.step()\n",
        "\n",
        "        ts = time.time()\n",
        "        for iter, batch in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if use_gpu:\n",
        "                inputs = Variable(batch['X'].cuda())\n",
        "                labels = Variable(batch['Y'].cuda())\n",
        "            else:\n",
        "                inputs, labels = Variable(batch['X']), Variable(batch['Y'])\n",
        "\n",
        "            outputs = fcn_model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if iter % 10 == 0:\n",
        "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.data.item()))\n",
        "        \n",
        "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
        "        \n",
        "\n",
        "        val(epoch)\n",
        "        \n",
        "    highest_pixel_acc = max(pixel_acc_list)\n",
        "    highest_mIOU = max(mIOU_list)        \n",
        "    \n",
        "    highest_pixel_acc_epoch = pixel_acc_list.index(highest_pixel_acc)\n",
        "    highest_mIOU_epoch = mIOU_list.index(highest_mIOU)\n",
        "    \n",
        "    print(\"The highest mIOU is {} and is achieved at epoch-{}\".format(highest_mIOU, highest_mIOU_epoch))\n",
        "    print(\"The highest pixel accuracy  is {} and is achieved at epoch-{}\".format(highest_pixel_acc, highest_pixel_acc_epoch))\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_result_comparison(input_np, output_np):\n",
        "    means     = np.array([103.939, 116.779, 123.68]) / 255.\n",
        "    \n",
        "    global global_index\n",
        "    \n",
        "    original_im_RGB = np.zeros((256,256,3))    \n",
        "    original_im_RGB[:,:,0] = input_np[0,0,:,:]    \n",
        "    original_im_RGB[:,:,1] = input_np[0,1,:,:]\n",
        "    original_im_RGB[:,:,2] = input_np[0,2,:,:]\n",
        "        \n",
        "    original_im_RGB[:,:,0] = original_im_RGB[:,:,0] + means[0]\n",
        "    original_im_RGB[:,:,1] = original_im_RGB[:,:,1] + means[1]\n",
        "    original_im_RGB[:,:,2] = original_im_RGB[:,:,2] + means[2]\n",
        "        \n",
        "    original_im_RGB[:,:,0] = original_im_RGB[:,:,0]*255.0\n",
        "    original_im_RGB[:,:,1] = original_im_RGB[:,:,1]*255.0\n",
        "    original_im_RGB[:,:,2] = original_im_RGB[:,:,2]*255.0\n",
        "    \n",
        "    im_seg_RGB = np.zeros((256,256,3))\n",
        "\n",
        "    # the following version is designed for 11-class version and could still work if the number of classes is fewer.\n",
        "    for i in range(256):\n",
        "        for j in range(256):\n",
        "            if output_np[i,j] == 0:\n",
        "                im_seg_RGB[i,j,:] = [128, 128, 128]\n",
        "            elif output_np[i,j] == 1:  \n",
        "                im_seg_RGB[i,j,:] = [128, 0, 0]\n",
        "            elif output_np[i,j] == 2:  \n",
        "                im_seg_RGB[i,j,:] = [192, 192, 128]    \n",
        "            elif output_np[i,j] == 3:  \n",
        "                im_seg_RGB[i,j,:] = [128, 64, 128]    \n",
        "            elif output_np[i,j] == 4:  \n",
        "                im_seg_RGB[i,j,:] = [0, 0, 192]    \n",
        "            elif output_np[i,j] == 5:  \n",
        "                im_seg_RGB[i,j,:] = [128, 128, 0]    \n",
        "            elif output_np[i,j] == 6:  \n",
        "                im_seg_RGB[i,j,:] = [192, 128, 128]    \n",
        "            elif output_np[i,j] == 7:  \n",
        "                im_seg_RGB[i,j,:] = [64, 64, 128]    \n",
        "            elif output_np[i,j] == 8:  \n",
        "                im_seg_RGB[i,j,:] = [64, 0, 128]    \n",
        "            elif output_np[i,j] == 9:  \n",
        "                im_seg_RGB[i,j,:] = [64, 64, 0]    \n",
        "            elif output_np[i,j] == 10:  \n",
        "                im_seg_RGB[i,j,:] = [0, 128, 192]    \n",
        "            else: im_seg_RGB[i,j,:] = [0, 0, 0]\n",
        "                    \n",
        "    # horizontally stack original image and its corresponding segmentation results     \n",
        "    hstack_image = np.hstack((original_im_RGB, im_seg_RGB))             \n",
        "    new_im = Image.fromarray(np.uint8(hstack_image))\n",
        "    \n",
        "    file_name = folder_to_save_validation_result +'class3-FCN32-'+ str(global_index) + '.jpg'\n",
        "        \n",
        "    global_index = global_index + 1\n",
        "        \n",
        "    new_im.save(file_name)       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E7cK6h9vkbf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d25e73bf-bd83-4571-a4a4-ac894686eb29"
      },
      "source": [
        "def val(epoch):\n",
        "    fcn_model.eval()\n",
        "    total_ious = []\n",
        "    pixel_accs = []\n",
        "                    \n",
        "    \n",
        "    for iter_, batch in enumerate(val_loader): ## batch is 1 in this case\n",
        "        if use_gpu:\n",
        "            inputs = Variable(batch['X'].cuda())\n",
        "        else:\n",
        "            inputs = Variable(batch['X'])        \n",
        "\n",
        "        output = fcn_model(inputs)                                \n",
        "        \n",
        "        # only save the 1st image for comparison\n",
        "        if iter_ == 0:\n",
        "            print('---------iter={}'.format(iter_))\n",
        "            # generate images\n",
        "            images = output.data.max(1)[1].cpu().numpy()[:,:,:]\n",
        "            image = images[0,:,:]        \n",
        "            save_result_comparison(batch['X'], image)\n",
        "                            \n",
        "        output = output.data.cpu().numpy()\n",
        "\n",
        "        N, _, h, w = output.shape                \n",
        "        pred = output.transpose(0, 2, 3, 1).reshape(-1, num_class).argmax(axis=1).reshape(N, h, w)        \n",
        "        target = batch['l'].cpu().numpy().reshape(N, h, w)\n",
        "\n",
        "        for p, t in zip(pred, target):\n",
        "            total_ious.append(iou(p, t))\n",
        "            pixel_accs.append(pixel_acc(p, t))\n",
        "\n",
        "    # Calculate average IoU\n",
        "    total_ious = np.array(total_ious).T  # n_class * val_len\n",
        "    ious = np.nanmean(total_ious, axis=1)\n",
        "    pixel_accs = np.array(pixel_accs).mean()\n",
        "    print(\"epoch{}, pix_acc: {}, meanIoU: {}, IoUs: {}\".format(epoch, pixel_accs, np.nanmean(ious), ious))\n",
        "    \n",
        "    global pixel_acc_list\n",
        "    global mIOU_list\n",
        "    \n",
        "    pixel_acc_list.append(pixel_accs)\n",
        "    mIOU_list.append(np.nanmean(ious))\n",
        "\n",
        "\n",
        "# borrow functions and modify it from https://github.com/Kaixhin/FCN-semantic-segmentation/blob/master/main.py\n",
        "# Calculates class intersections over unions\n",
        "def iou(pred, target):\n",
        "    ious = []\n",
        "    for cls in range(num_class):\n",
        "        pred_inds = pred == cls\n",
        "        target_inds = target == cls\n",
        "        intersection = pred_inds[target_inds].sum()\n",
        "        union = pred_inds.sum() + target_inds.sum() - intersection\n",
        "        if union == 0:\n",
        "            ious.append(float('nan'))  # if there is no ground truth, do not include in evaluation\n",
        "        else:\n",
        "            ious.append(float(intersection) / max(union, 1))\n",
        "        # print(\"cls\", cls, pred_inds.sum(), target_inds.sum(), intersection, float(intersection) / max(union, 1))\n",
        "    return ious\n",
        "\n",
        "\n",
        "def pixel_acc(pred, target):\n",
        "    correct = (pred == target).sum()\n",
        "    total   = (target == target).sum()\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "## perform training and validation\n",
        "val(0)  # show the accuracy before training\n",
        "print('===== start training ====')\n",
        "train()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------iter=0\n",
            "epoch0, pix_acc: 0.12593643188476564, meanIoU: 0.06558178458529491, IoUs: [0.11142992 0.0812266  0.00408883]\n",
            "===== start training ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch0, iter0, loss: 0.6758131384849548\n",
            "epoch0, iter10, loss: 0.5448307991027832\n",
            "epoch0, iter20, loss: 0.3455128073692322\n",
            "epoch0, iter30, loss: 0.30143412947654724\n",
            "epoch0, iter40, loss: 0.32099929451942444\n",
            "epoch0, iter50, loss: 0.25931110978126526\n",
            "epoch0, iter60, loss: 0.22353750467300415\n",
            "Finish epoch 0, time elapsed 342.74272894859314\n",
            "---------iter=0\n",
            "epoch0, pix_acc: 0.24779006958007813, meanIoU: 0.1691888194943372, IoUs: [0.284084   0.22348246 0.        ]\n",
            "epoch1, iter0, loss: 0.2143314629793167\n",
            "epoch1, iter10, loss: 0.24473853409290314\n",
            "epoch1, iter20, loss: 0.19676919281482697\n",
            "epoch1, iter30, loss: 0.13048812747001648\n",
            "epoch1, iter40, loss: 0.12789875268936157\n",
            "epoch1, iter50, loss: 0.146952822804451\n",
            "epoch1, iter60, loss: 0.12826067209243774\n",
            "Finish epoch 1, time elapsed 13.226037740707397\n",
            "---------iter=0\n",
            "epoch1, pix_acc: 0.30782257080078124, meanIoU: 0.25141517325403073, IoUs: [5.05737333e-01 2.48146296e-01 3.61890652e-04]\n",
            "epoch2, iter0, loss: 0.1370067298412323\n",
            "epoch2, iter10, loss: 0.11440224200487137\n",
            "epoch2, iter20, loss: 0.09822661429643631\n",
            "epoch2, iter30, loss: 0.10127736628055573\n",
            "epoch2, iter40, loss: 0.101362444460392\n",
            "epoch2, iter50, loss: 0.10119625180959702\n",
            "epoch2, iter60, loss: 0.08610855042934418\n",
            "Finish epoch 2, time elapsed 13.32347822189331\n",
            "---------iter=0\n",
            "epoch2, pix_acc: 0.32092803955078125, meanIoU: 0.35768279614645787, IoUs: [8.17289823e-01 2.55482540e-01 2.76025898e-04]\n",
            "epoch3, iter0, loss: 0.08674267679452896\n",
            "epoch3, iter10, loss: 0.09821435809135437\n",
            "epoch3, iter20, loss: 0.11446438729763031\n",
            "epoch3, iter30, loss: 0.12094267457723618\n",
            "epoch3, iter40, loss: 0.07610610127449036\n",
            "epoch3, iter50, loss: 0.093692347407341\n",
            "epoch3, iter60, loss: 0.08556864410638809\n",
            "Finish epoch 3, time elapsed 13.421553373336792\n",
            "---------iter=0\n",
            "epoch3, pix_acc: 0.31971786499023436, meanIoU: 0.349329405334937, IoUs: [7.66077504e-01 2.81456934e-01 4.53777402e-04]\n",
            "epoch4, iter0, loss: 0.11039510369300842\n",
            "epoch4, iter10, loss: 0.08759728819131851\n",
            "epoch4, iter20, loss: 0.07475890219211578\n",
            "epoch4, iter30, loss: 0.08230330049991608\n",
            "epoch4, iter40, loss: 0.1285865306854248\n",
            "epoch4, iter50, loss: 0.0802733451128006\n",
            "epoch4, iter60, loss: 0.14215102791786194\n",
            "Finish epoch 4, time elapsed 13.50458312034607\n",
            "---------iter=0\n",
            "epoch4, pix_acc: 0.321923828125, meanIoU: 0.3645843169460852, IoUs: [8.29053025e-01 2.64544562e-01 1.55363840e-04]\n",
            "epoch5, iter0, loss: 0.08843743801116943\n",
            "epoch5, iter10, loss: 0.08789949864149094\n",
            "epoch5, iter20, loss: 0.09992764890193939\n",
            "epoch5, iter30, loss: 0.08603862673044205\n",
            "epoch5, iter40, loss: 0.07894405722618103\n",
            "epoch5, iter50, loss: 0.0674041137099266\n",
            "epoch5, iter60, loss: 0.08482285588979721\n",
            "Finish epoch 5, time elapsed 13.54285216331482\n",
            "---------iter=0\n",
            "epoch5, pix_acc: 0.32192535400390626, meanIoU: 0.3641228673307843, IoUs: [8.16181926e-01 2.76053221e-01 1.33455737e-04]\n",
            "epoch6, iter0, loss: 0.09101555496454239\n",
            "epoch6, iter10, loss: 0.05652301385998726\n",
            "epoch6, iter20, loss: 0.09490355104207993\n",
            "epoch6, iter30, loss: 0.08397690951824188\n",
            "epoch6, iter40, loss: 0.07763495296239853\n",
            "epoch6, iter50, loss: 0.08480776101350784\n",
            "epoch6, iter60, loss: 0.09540312737226486\n",
            "Finish epoch 6, time elapsed 13.689445972442627\n",
            "---------iter=0\n",
            "epoch6, pix_acc: 0.3162272644042969, meanIoU: 0.30042597689297906, IoUs: [0.48330662 0.41582573 0.00214558]\n",
            "epoch7, iter0, loss: 0.08501332253217697\n",
            "epoch7, iter10, loss: 0.10205747187137604\n",
            "epoch7, iter20, loss: 0.09287033975124359\n",
            "epoch7, iter30, loss: 0.06483177095651627\n",
            "epoch7, iter40, loss: 0.05811113864183426\n",
            "epoch7, iter50, loss: 0.07210184633731842\n",
            "epoch7, iter60, loss: 0.08996668457984924\n",
            "Finish epoch 7, time elapsed 13.807517766952515\n",
            "---------iter=0\n",
            "epoch7, pix_acc: 0.3207188415527344, meanIoU: 0.44534304631295735, IoUs: [0.85885497 0.47553459 0.00163958]\n",
            "epoch8, iter0, loss: 0.07641144841909409\n",
            "epoch8, iter10, loss: 0.08996525406837463\n",
            "epoch8, iter20, loss: 0.0636267438530922\n",
            "epoch8, iter30, loss: 0.08473972231149673\n",
            "epoch8, iter40, loss: 0.0928148403763771\n",
            "epoch8, iter50, loss: 0.07539064437150955\n",
            "epoch8, iter60, loss: 0.07417557388544083\n",
            "Finish epoch 8, time elapsed 13.908826112747192\n",
            "---------iter=0\n",
            "epoch8, pix_acc: 0.3217372131347656, meanIoU: 0.44978661906219747, IoUs: [0.80853133 0.53939938 0.00142915]\n",
            "epoch9, iter0, loss: 0.07367600500583649\n",
            "epoch9, iter10, loss: 0.07034169882535934\n",
            "epoch9, iter20, loss: 0.06695293635129929\n",
            "epoch9, iter30, loss: 0.07465577125549316\n",
            "epoch9, iter40, loss: 0.08045827597379684\n",
            "epoch9, iter50, loss: 0.07550834119319916\n",
            "epoch9, iter60, loss: 0.05932733789086342\n",
            "Finish epoch 9, time elapsed 13.958566904067993\n",
            "---------iter=0\n",
            "epoch9, pix_acc: 0.322449951171875, meanIoU: 0.4391618248569203, IoUs: [0.81182028 0.50377197 0.00189323]\n",
            "epoch10, iter0, loss: 0.08115817606449127\n",
            "epoch10, iter10, loss: 0.06836550682783127\n",
            "epoch10, iter20, loss: 0.06373480707406998\n",
            "epoch10, iter30, loss: 0.05607195571064949\n",
            "epoch10, iter40, loss: 0.04712706059217453\n",
            "epoch10, iter50, loss: 0.06516630202531815\n",
            "epoch10, iter60, loss: 0.05984824150800705\n",
            "Finish epoch 10, time elapsed 14.032216310501099\n",
            "---------iter=0\n",
            "epoch10, pix_acc: 0.32239776611328125, meanIoU: 0.47511925782787917, IoUs: [0.82595952 0.59687245 0.00252581]\n",
            "epoch11, iter0, loss: 0.04640941694378853\n",
            "epoch11, iter10, loss: 0.08159032464027405\n",
            "epoch11, iter20, loss: 0.059564173221588135\n",
            "epoch11, iter30, loss: 0.06043754145503044\n",
            "epoch11, iter40, loss: 0.06571165472269058\n",
            "epoch11, iter50, loss: 0.0578429251909256\n",
            "epoch11, iter60, loss: 0.07102707773447037\n",
            "Finish epoch 11, time elapsed 13.880853652954102\n",
            "---------iter=0\n",
            "epoch11, pix_acc: 0.32284042358398435, meanIoU: 0.4332098911585125, IoUs: [0.8420524  0.45590828 0.00166899]\n",
            "epoch12, iter0, loss: 0.06182925030589104\n",
            "epoch12, iter10, loss: 0.06702001392841339\n",
            "epoch12, iter20, loss: 0.06733380258083344\n",
            "epoch12, iter30, loss: 0.061600856482982635\n",
            "epoch12, iter40, loss: 0.07661797106266022\n",
            "epoch12, iter50, loss: 0.07173363119363785\n",
            "epoch12, iter60, loss: 0.06717918068170547\n",
            "Finish epoch 12, time elapsed 13.887943506240845\n",
            "---------iter=0\n",
            "epoch12, pix_acc: 0.32386505126953125, meanIoU: 0.4388685043313971, IoUs: [0.78764638 0.52642729 0.00253185]\n",
            "epoch13, iter0, loss: 0.05539088323712349\n",
            "epoch13, iter10, loss: 0.06748364865779877\n",
            "epoch13, iter20, loss: 0.06073033809661865\n",
            "epoch13, iter30, loss: 0.06985405087471008\n",
            "epoch13, iter40, loss: 0.07242320477962494\n",
            "epoch13, iter50, loss: 0.06320951133966446\n",
            "epoch13, iter60, loss: 0.0643327385187149\n",
            "Finish epoch 13, time elapsed 13.981388092041016\n",
            "---------iter=0\n",
            "epoch13, pix_acc: 0.3236933898925781, meanIoU: 0.41777686453713664, IoUs: [0.75759669 0.49350879 0.00222511]\n",
            "epoch14, iter0, loss: 0.05625257268548012\n",
            "epoch14, iter10, loss: 0.06363695114850998\n",
            "epoch14, iter20, loss: 0.06544233858585358\n",
            "epoch14, iter30, loss: 0.057262733578681946\n",
            "epoch14, iter40, loss: 0.06938985735177994\n",
            "epoch14, iter50, loss: 0.056648559868335724\n",
            "epoch14, iter60, loss: 0.08038633316755295\n",
            "Finish epoch 14, time elapsed 13.916393280029297\n",
            "---------iter=0\n",
            "epoch14, pix_acc: 0.32284393310546877, meanIoU: 0.310021348997879, IoUs: [0.62511475 0.3035768  0.0013725 ]\n",
            "epoch15, iter0, loss: 0.07432083785533905\n",
            "epoch15, iter10, loss: 0.07042212784290314\n",
            "epoch15, iter20, loss: 0.053914204239845276\n",
            "epoch15, iter30, loss: 0.06982511281967163\n",
            "epoch15, iter40, loss: 0.08278588950634003\n",
            "epoch15, iter50, loss: 0.057620830833911896\n",
            "epoch15, iter60, loss: 0.06676536798477173\n",
            "Finish epoch 15, time elapsed 13.950485229492188\n",
            "---------iter=0\n",
            "epoch15, pix_acc: 0.323670654296875, meanIoU: 0.41050207160904756, IoUs: [0.74148401 0.48672664 0.00329556]\n",
            "epoch16, iter0, loss: 0.05347135290503502\n",
            "epoch16, iter10, loss: 0.054072409868240356\n",
            "epoch16, iter20, loss: 0.07370010763406754\n",
            "epoch16, iter30, loss: 0.04987502843141556\n",
            "epoch16, iter40, loss: 0.058714549988508224\n",
            "epoch16, iter50, loss: 0.03959338739514351\n",
            "epoch16, iter60, loss: 0.05188421532511711\n",
            "Finish epoch 16, time elapsed 14.043161630630493\n",
            "---------iter=0\n",
            "epoch16, pix_acc: 0.3232838439941406, meanIoU: 0.382818139056764, IoUs: [0.74838533 0.39600775 0.00406133]\n",
            "epoch17, iter0, loss: 0.05819156393408775\n",
            "epoch17, iter10, loss: 0.059512216597795486\n",
            "epoch17, iter20, loss: 0.04444992542266846\n",
            "epoch17, iter30, loss: 0.04526815935969353\n",
            "epoch17, iter40, loss: 0.06785360723733902\n",
            "epoch17, iter50, loss: 0.07494203001260757\n",
            "epoch17, iter60, loss: 0.07057608664035797\n",
            "Finish epoch 17, time elapsed 13.926241874694824\n",
            "---------iter=0\n",
            "epoch17, pix_acc: 0.32354537963867186, meanIoU: 0.36297106174432714, IoUs: [0.6893084  0.39579744 0.00380734]\n",
            "epoch18, iter0, loss: 0.051870569586753845\n",
            "epoch18, iter10, loss: 0.06784162670373917\n",
            "epoch18, iter20, loss: 0.06385239958763123\n",
            "epoch18, iter30, loss: 0.052158091217279434\n",
            "epoch18, iter40, loss: 0.08072788268327713\n",
            "epoch18, iter50, loss: 0.04686105251312256\n",
            "epoch18, iter60, loss: 0.0586840845644474\n",
            "Finish epoch 18, time elapsed 14.027529239654541\n",
            "---------iter=0\n",
            "epoch18, pix_acc: 0.3237646484375, meanIoU: 0.390286298529635, IoUs: [0.66037772 0.50778257 0.00269861]\n",
            "epoch19, iter0, loss: 0.05411742255091667\n",
            "epoch19, iter10, loss: 0.059822600334882736\n",
            "epoch19, iter20, loss: 0.07645879685878754\n",
            "epoch19, iter30, loss: 0.05114362761378288\n",
            "epoch19, iter40, loss: 0.06557543575763702\n",
            "epoch19, iter50, loss: 0.046704500913619995\n",
            "epoch19, iter60, loss: 0.05464249849319458\n",
            "Finish epoch 19, time elapsed 14.043001890182495\n",
            "---------iter=0\n",
            "epoch19, pix_acc: 0.31963104248046875, meanIoU: 0.46723184436880993, IoUs: [0.79548132 0.60214868 0.00406554]\n",
            "The highest mIOU is 0.47511925782787917 and is achieved at epoch-11\n",
            "The highest pixel accuracy  is 0.32386505126953125 and is achieved at epoch-13\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}