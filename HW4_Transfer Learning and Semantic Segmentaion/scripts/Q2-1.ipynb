{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Q2-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6MlHCEAdZPy1"
      },
      "source": [
        "**Initial step:** Please try to put the extracted CamVid folder in your Google Drive!\n",
        "So now you could mount your data to this ipynb!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UGAXY5HMYjzL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "0f9f7ea9-e7c3-490b-c490-8112201c830e"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wTBYCMcpZoA8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "b4bb62a5-7eaf-4437-d807-6914db008262"
      },
      "source": [
        "# if you mount Google drive correctly, the following commands should be able to executed correctly\n",
        "!ls /content/drive/\n",
        "%cd \"/content/drive/My Drive\"\n",
        "%cd \"CamVid\"\n",
        "\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'My Drive'  'Shared drives'\n",
            "/content/drive/My Drive\n",
            "/content/drive/My Drive/CamVid\n",
            "result_comparision  train  trainannot  train.csv  val  valannot  val.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pfWmPZKyZ8gA",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import utils\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torchvision.models.vgg import VGG\n",
        "import random\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "from os import path\n",
        "\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torchvision.models.vgg import VGG\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YMzL2KhcaI9u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4125f388-0df9-4708-8cc9-136dd128b592"
      },
      "source": [
        "#root_dir = './CamVid/'\n",
        "root_dir   = \"/content/drive/My Drive/CamVid/\"\n",
        "train_file = os.path.join(root_dir, \"train.csv\")\n",
        "val_file   = os.path.join(root_dir, \"val.csv\")\n",
        "\n",
        "print(\"training csv exits:{}\".format(path.exists(train_file)))\n",
        "print(\"validation csv exits:{}\".format(path.exists(val_file)))\n",
        "\n",
        "# the folder to save results for comparison\n",
        "folder_to_save_validation_result = root_dir + '/result_comparision/' \n",
        "\n",
        "if os.path.isdir(folder_to_save_validation_result) == False:\n",
        "    os.mkdir(folder_to_save_validation_result)\n",
        "\n",
        "\n",
        "# the number of segmentation classes\n",
        "num_class = 11 # 32 for original CamVid\n",
        "means     = np.array([103.939, 116.779, 123.68]) / 255. # mean of three channels in the order of BGR\n",
        "\n",
        "h, w      = 256, 256\n",
        "train_h = 256\n",
        "train_w = 256\n",
        "val_h = 256\n",
        "val_w = 256\n",
        "\n",
        "## parameters for Solver-Adam in this example\n",
        "batch_size = 6 #\n",
        "epochs     = 20 # don't try to improve the performance by simply increasing the training epochs or iterations\n",
        "lr         = 1e-4    # achieved besty results \n",
        "step_size  = 100 # Won't work when epochs <=100\n",
        "gamma      = 0.5 # \n",
        "#\n",
        "\n",
        "## index for validation images\n",
        "global_index = 0\n",
        "\n",
        "# pixel accuracy and mIOU list \n",
        "pixel_acc_list = []\n",
        "mIOU_list = []\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "num_gpu = list(range(torch.cuda.device_count()))\n",
        "\n",
        "class CamVidDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file, phase, n_class=num_class, crop=True, flip_rate=0.5):\n",
        "        self.data      = pd.read_csv(csv_file)\n",
        "        self.means     = means\n",
        "        self.n_class   = n_class\n",
        "        self.flip_rate = flip_rate       \n",
        "\n",
        "        self.resize_h = h\n",
        "        self.resize_w = w        \n",
        "        \n",
        "        if phase == 'train':\n",
        "            self.new_h = train_h\n",
        "            self.new_w = train_w\n",
        "            self.crop = crop\n",
        "        elif phase == 'val':\n",
        "            self.flip_rate = 0.\n",
        "            self.crop = False # False\n",
        "            self.new_h = val_h\n",
        "            self.new_w = val_w\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name   = self.data.iloc[idx, 0]                \n",
        "        img_name = root_dir  + img_name                        \n",
        "        img = Image.open(img_name).convert('RGB')  \n",
        "\n",
        "        label_name = self.data.iloc[idx, 1]        \n",
        "        label_name = root_dir  + label_name                       \n",
        "        label_image = Image.open(label_name)\n",
        "        label = np.asarray(label_image)\n",
        "\n",
        "        # In training mode, the crop strategy is random-shift crop.\n",
        "        # In validation model, it is center crop.\n",
        "        if self.crop:            \n",
        "            w, h = img.size\n",
        "            A_x_offset = np.int32(np.random.randint(0, w - self.new_w + 1, 1))[0]\n",
        "            A_y_offset = np.int32(np.random.randint(0, h - self.new_h + 1, 1))[0]\n",
        "\n",
        "            img = img.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n",
        "            label_image = label_image.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n",
        "        else:            \n",
        "            w, h = img.size\n",
        "            A_x_offset = int((w - self.new_w)/2)\n",
        "            A_y_offset = int((h - self.new_h)/2)\n",
        "            \n",
        "            img = img.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n",
        "            label_image = label_image.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n",
        "\n",
        "            label_image_h, label_image_w = label_image.size\n",
        "\n",
        "        # we could try to revise the values in label for reducing the number of segmentation classes\n",
        "        label = np.array(label_image)              \n",
        "\n",
        "        if random.random() < self.flip_rate:\n",
        "            img   = np.fliplr(img)\n",
        "            label = np.fliplr(label)\n",
        "        \n",
        "        # reduce mean in terms of BGR\n",
        "        img = np.transpose(img, (2, 0, 1)) / 255.\n",
        "        img[0] -= self.means[0]\n",
        "        img[1] -= self.means[1]\n",
        "        img[2] -= self.means[2]\n",
        "\n",
        "        # convert to tensor\n",
        "        img = torch.from_numpy(img.copy()).float()\n",
        "        label = torch.from_numpy(label.copy()).long()\n",
        "\n",
        "        # create one-hot encoding  ???????\n",
        "        h, w = label.size()\n",
        "        target = torch.zeros(self.n_class, h, w)\n",
        "        for c in range(self.n_class):\n",
        "            target[c][label == c] = 1\n",
        "\n",
        "        sample = {'X': img, 'Y': target, 'l': label}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "train_data = CamVidDataset(csv_file=train_file, phase='train')\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "val_data = CamVidDataset(csv_file=val_file, phase='val', flip_rate=0)\n",
        "val_loader = DataLoader(val_data, batch_size=1, num_workers=0)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training csv exits:True\n",
            "validation csv exits:True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4h-a5moWhLhF",
        "colab": {}
      },
      "source": [
        "# cropped version from https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\n",
        "cfg = {\n",
        "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "ranges = {\n",
        "    'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n",
        "    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n",
        "    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n",
        "    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n",
        "}\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class VGGNet(VGG):\n",
        "    def __init__(self, pretrained=True, model='vgg16', requires_grad=True, remove_fc=True, show_params=False):\n",
        "        super().__init__(make_layers(cfg[model]))\n",
        "        self.ranges = ranges[model]\n",
        "\n",
        "        if pretrained:            \n",
        "            exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n",
        "\n",
        "        if not requires_grad:\n",
        "            for param in super().parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        if remove_fc:  # delete redundant fully-connected layer params, can save memory\n",
        "            del self.classifier\n",
        "\n",
        "        if show_params:\n",
        "            for name, param in self.named_parameters():\n",
        "                print(name, param.size())\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = {}\n",
        "\n",
        "        # get the output of each maxpooling layer (5 maxpool in VGG net)\n",
        "        for idx in range(len(self.ranges)):\n",
        "            for layer in range(self.ranges[idx][0], self.ranges[idx][1]):\n",
        "                x = self.features[layer](x)\n",
        "            output[\"x%d\"%(idx+1)] = x\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRNE6nfyY-9j",
        "colab_type": "text"
      },
      "source": [
        "### Q2-1. Please try to “eliminate” the skip-connection so the output of convolution layers of FCN8s will be directly upsampled for 32x. Please report pixel accuracy and mIOU before and after. (10 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSE1V2XGY-9p",
        "colab_type": "text"
      },
      "source": [
        "##### step 1 : eliminate the skip-connection \"x3\",\"x4\" in FCN8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JjRRa-QY-9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FCN8s(nn.Module):\n",
        "    #Ref: https://towardsdatascience.com/review-fcn-semantic-segmentation-eb8c9b50d2d1\n",
        "    #The layer description is accordance with the above fiture instead of the original paper. Alex 2019/12/03 \n",
        "    def __init__(self, pretrained_net, n_class):\n",
        "        super().__init__()\n",
        "        self.n_class = n_class\n",
        "        self.pretrained_net = pretrained_net\n",
        "        self.relu    = nn.ReLU(inplace=True)\n",
        "        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        #self.bn1     = nn.BatchNorm2d(512)\n",
        "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        #self.bn2     = nn.BatchNorm2d(256)\n",
        "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        #self.bn3     = nn.BatchNorm2d(128)\n",
        "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        #self.bn4     = nn.BatchNorm2d(64)\n",
        "        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        #self.bn5     = nn.BatchNorm2d(32)\n",
        "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.pretrained_net(x)\n",
        "        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n",
        "        #x4 = output['x4']  # size=(N, 512, x.H/16, x.W/16)\n",
        "        #x3 = output['x3']  # size=(N, 256, x.H/8,  x.W/8)\n",
        "\n",
        "        score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n",
        "        #score = self.bn1(score + x4)                      # element-wise add, size=(N, 512, x.H/16, x.W/16)                      \n",
        "        score = self.relu(self.deconv2(score))            # size=(N, 256, x.H/8, x.W/8)\n",
        "       # score = self.bn2(score + x3)                      # element-wise add, size=(N, 256, x.H/8, x.W/8)           \n",
        "        \n",
        "        #score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n",
        "        #score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n",
        "        #score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n",
        "        score = self.relu(self.deconv3(score))   ##??沒了x3,x4還需要batch normalize嗎?\n",
        "        score = self.relu(self.deconv4(score))\n",
        "        score = self.relu(self.deconv5(score))\n",
        "        \n",
        "        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n",
        "\n",
        "        return score  # size=(N, n_class, x.H/1, x.W/1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py0n3j1uY-92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "40527f67-2750-4efc-8cdb-3c560b1b1c33"
      },
      "source": [
        "# load pretrained weights and define FCN8s\n",
        "vgg_model = VGGNet(requires_grad=True, remove_fc=True)\n",
        "fcn_model = FCN8s(pretrained_net=vgg_model, n_class=num_class)\n",
        "\n",
        "ts = time.time()\n",
        "vgg_model = vgg_model.cuda()\n",
        "fcn_model = fcn_model.cuda()\n",
        "fcn_model = nn.DataParallel(fcn_model, device_ids=num_gpu)\n",
        "print(\"Finish cuda loading, time elapsed {}\".format(time.time() - ts))\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(fcn_model.parameters(), lr=lr)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)  "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:10<00:00, 53.2MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finish cuda loading, time elapsed 9.485878705978394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNp4ET-8Y-9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(fcn_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lUjPeffKbm36",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    for epoch in range(epochs):\n",
        "        scheduler.step()\n",
        "\n",
        "        ts = time.time()\n",
        "        for iter, batch in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if use_gpu:\n",
        "                inputs = Variable(batch['X'].cuda())\n",
        "                labels = Variable(batch['Y'].cuda())\n",
        "            else:\n",
        "                inputs, labels = Variable(batch['X']), Variable(batch['Y'])\n",
        "\n",
        "            outputs = fcn_model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if iter % 10 == 0:\n",
        "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.data.item()))\n",
        "        \n",
        "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
        "        \n",
        "\n",
        "        val(epoch)\n",
        "        \n",
        "    highest_pixel_acc = max(pixel_acc_list)\n",
        "    highest_mIOU = max(mIOU_list)        \n",
        "    \n",
        "    highest_pixel_acc_epoch = pixel_acc_list.index(highest_pixel_acc)\n",
        "    highest_mIOU_epoch = mIOU_list.index(highest_mIOU)\n",
        "    \n",
        "    print(\"The highest mIOU is {} and is achieved at epoch-{}\".format(highest_mIOU, highest_mIOU_epoch))\n",
        "    print(\"The highest pixel accuracy  is {} and is achieved at epoch-{}\".format(highest_pixel_acc, highest_pixel_acc_epoch))\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_result_comparison(input_np, output_np):\n",
        "    means     = np.array([103.939, 116.779, 123.68]) / 255.\n",
        "    \n",
        "    global global_index\n",
        "    \n",
        "    original_im_RGB = np.zeros((256,256,3))    \n",
        "    original_im_RGB[:,:,0] = input_np[0,0,:,:]    \n",
        "    original_im_RGB[:,:,1] = input_np[0,1,:,:]\n",
        "    original_im_RGB[:,:,2] = input_np[0,2,:,:]\n",
        "        \n",
        "    original_im_RGB[:,:,0] = original_im_RGB[:,:,0] + means[0]\n",
        "    original_im_RGB[:,:,1] = original_im_RGB[:,:,1] + means[1]\n",
        "    original_im_RGB[:,:,2] = original_im_RGB[:,:,2] + means[2]\n",
        "        \n",
        "    original_im_RGB[:,:,0] = original_im_RGB[:,:,0]*255.0\n",
        "    original_im_RGB[:,:,1] = original_im_RGB[:,:,1]*255.0\n",
        "    original_im_RGB[:,:,2] = original_im_RGB[:,:,2]*255.0\n",
        "    \n",
        "    im_seg_RGB = np.zeros((256,256,3))\n",
        "\n",
        "    # the following version is designed for 11-class version and could still work if the number of classes is fewer.\n",
        "    for i in range(256):\n",
        "        for j in range(256):\n",
        "            if output_np[i,j] == 0:\n",
        "                im_seg_RGB[i,j,:] = [128, 128, 128]\n",
        "            elif output_np[i,j] == 1:  \n",
        "                im_seg_RGB[i,j,:] = [128, 0, 0]\n",
        "            elif output_np[i,j] == 2:  \n",
        "                im_seg_RGB[i,j,:] = [192, 192, 128]    \n",
        "            elif output_np[i,j] == 3:  \n",
        "                im_seg_RGB[i,j,:] = [128, 64, 128]    \n",
        "            elif output_np[i,j] == 4:  \n",
        "                im_seg_RGB[i,j,:] = [0, 0, 192]    \n",
        "            elif output_np[i,j] == 5:  \n",
        "                im_seg_RGB[i,j,:] = [128, 128, 0]    \n",
        "            elif output_np[i,j] == 6:  \n",
        "                im_seg_RGB[i,j,:] = [192, 128, 128]    \n",
        "            elif output_np[i,j] == 7:  \n",
        "                im_seg_RGB[i,j,:] = [64, 64, 128]    \n",
        "            elif output_np[i,j] == 8:  \n",
        "                im_seg_RGB[i,j,:] = [64, 0, 128]    \n",
        "            elif output_np[i,j] == 9:  \n",
        "                im_seg_RGB[i,j,:] = [64, 64, 0]    \n",
        "            elif output_np[i,j] == 10:  \n",
        "                im_seg_RGB[i,j,:] = [0, 128, 192]    \n",
        "            else: im_seg_RGB[i,j,:] = [0, 0, 0]\n",
        "                    \n",
        "    # horizontally stack original image and its corresponding segmentation results     \n",
        "    hstack_image = np.hstack((original_im_RGB, im_seg_RGB))             \n",
        "    new_im = Image.fromarray(np.uint8(hstack_image))\n",
        "    \n",
        "    file_name = folder_to_save_validation_result +'FCN32-'+ str(global_index) + '.jpg'\n",
        "        \n",
        "    global_index = global_index + 1\n",
        "        \n",
        "    new_im.save(file_name)       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E7cK6h9vkbf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1285df70-1bf4-49d9-ce1b-6146a0016c8e"
      },
      "source": [
        "def val(epoch):\n",
        "    fcn_model.eval()\n",
        "    total_ious = []\n",
        "    pixel_accs = []\n",
        "                    \n",
        "    \n",
        "    for iter_, batch in enumerate(val_loader): ## batch is 1 in this case\n",
        "        if use_gpu:\n",
        "            inputs = Variable(batch['X'].cuda())\n",
        "        else:\n",
        "            inputs = Variable(batch['X'])        \n",
        "\n",
        "        output = fcn_model(inputs)                                \n",
        "        \n",
        "        # only save the 1st image for comparison\n",
        "        if iter_ == 0:\n",
        "            print('---------iter={}'.format(iter_))\n",
        "            # generate images\n",
        "            images = output.data.max(1)[1].cpu().numpy()[:,:,:]\n",
        "            image = images[0,:,:]        \n",
        "            save_result_comparison(batch['X'], image)\n",
        "                            \n",
        "        output = output.data.cpu().numpy()\n",
        "\n",
        "        N, _, h, w = output.shape                \n",
        "        pred = output.transpose(0, 2, 3, 1).reshape(-1, num_class).argmax(axis=1).reshape(N, h, w)        \n",
        "        target = batch['l'].cpu().numpy().reshape(N, h, w)\n",
        "\n",
        "        for p, t in zip(pred, target):\n",
        "            total_ious.append(iou(p, t))\n",
        "            pixel_accs.append(pixel_acc(p, t))\n",
        "\n",
        "    # Calculate average IoU\n",
        "    total_ious = np.array(total_ious).T  # n_class * val_len\n",
        "    ious = np.nanmean(total_ious, axis=1)\n",
        "    pixel_accs = np.array(pixel_accs).mean()\n",
        "    print(\"epoch{}, pix_acc: {}, meanIoU: {}, IoUs: {}\".format(epoch, pixel_accs, np.nanmean(ious), ious))\n",
        "    \n",
        "    global pixel_acc_list\n",
        "    global mIOU_list\n",
        "    \n",
        "    pixel_acc_list.append(pixel_accs)\n",
        "    mIOU_list.append(np.nanmean(ious))\n",
        "\n",
        "\n",
        "# borrow functions and modify it from https://github.com/Kaixhin/FCN-semantic-segmentation/blob/master/main.py\n",
        "# Calculates class intersections over unions\n",
        "def iou(pred, target):\n",
        "    ious = []\n",
        "    for cls in range(num_class):\n",
        "        pred_inds = pred == cls\n",
        "        target_inds = target == cls\n",
        "        intersection = pred_inds[target_inds].sum()\n",
        "        union = pred_inds.sum() + target_inds.sum() - intersection\n",
        "        if union == 0:\n",
        "            ious.append(float('nan'))  # if there is no ground truth, do not include in evaluation\n",
        "        else:\n",
        "            ious.append(float(intersection) / max(union, 1))\n",
        "        # print(\"cls\", cls, pred_inds.sum(), target_inds.sum(), intersection, float(intersection) / max(union, 1))\n",
        "    return ious\n",
        "\n",
        "\n",
        "def pixel_acc(pred, target):\n",
        "    correct = (pred == target).sum()\n",
        "    total   = (target == target).sum()\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "## perform training and validation\n",
        "val(0)  # show the accuracy before training\n",
        "print('===== start training ====')\n",
        "train()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------iter=0\n",
            "epoch0, pix_acc: 0.006816864013671875, meanIoU: 0.0006197149103338069, IoUs: [0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.00681686 0.        ]\n",
            "===== start training ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch0, iter0, loss: 0.6920765042304993\n",
            "epoch0, iter10, loss: 0.6421383023262024\n",
            "epoch0, iter20, loss: 0.5102478265762329\n",
            "epoch0, iter30, loss: 0.4133835732936859\n",
            "epoch0, iter40, loss: 0.3552585542201996\n",
            "epoch0, iter50, loss: 0.2974878251552582\n",
            "epoch0, iter60, loss: 0.2676509916782379\n",
            "Finish epoch 0, time elapsed 227.9252679347992\n",
            "---------iter=0\n",
            "epoch0, pix_acc: 0.28945724487304686, meanIoU: 0.03764174871423169, IoUs: [0.02252377 0.09370078 0.00105987 0.28754804 0.         0.00416738\n",
            " 0.00098115 0.001158   0.00292024 0.         0.        ]\n",
            "epoch1, iter0, loss: 0.2542753219604492\n",
            "epoch1, iter10, loss: 0.24574069678783417\n",
            "epoch1, iter20, loss: 0.21749630570411682\n",
            "epoch1, iter30, loss: 0.20569784939289093\n",
            "epoch1, iter40, loss: 0.21285118162631989\n",
            "epoch1, iter50, loss: 0.17907021939754486\n",
            "epoch1, iter60, loss: 0.19450879096984863\n",
            "Finish epoch 1, time elapsed 8.07913851737976\n",
            "---------iter=0\n",
            "epoch1, pix_acc: 0.5071649169921875, meanIoU: 0.11102515422761478, IoUs: [1.17075064e-01 3.24969638e-01 1.08786180e-03 7.57749330e-01\n",
            " 1.80996587e-03 3.14103717e-03 0.00000000e+00 6.23532737e-05\n",
            " 1.53814470e-02 0.00000000e+00 0.00000000e+00]\n",
            "epoch2, iter0, loss: 0.15292078256607056\n",
            "epoch2, iter10, loss: 0.15145070850849152\n",
            "epoch2, iter20, loss: 0.18688970804214478\n",
            "epoch2, iter30, loss: 0.14997759461402893\n",
            "epoch2, iter40, loss: 0.13357137143611908\n",
            "epoch2, iter50, loss: 0.12769734859466553\n",
            "epoch2, iter60, loss: 0.13852952420711517\n",
            "Finish epoch 2, time elapsed 7.904106616973877\n",
            "---------iter=0\n",
            "epoch2, pix_acc: 0.6105917358398437, meanIoU: 0.16999849401874353, IoUs: [6.07118243e-01 4.72371048e-01 2.48951305e-04 7.13775574e-01\n",
            " 5.62432411e-03 1.08387340e-02 0.00000000e+00 1.50328177e-03\n",
            " 5.85032774e-02 0.00000000e+00 0.00000000e+00]\n",
            "epoch3, iter0, loss: 0.10946007817983627\n",
            "epoch3, iter10, loss: 0.1230359822511673\n",
            "epoch3, iter20, loss: 0.12054287642240524\n",
            "epoch3, iter30, loss: 0.11500979959964752\n",
            "epoch3, iter40, loss: 0.13679657876491547\n",
            "epoch3, iter50, loss: 0.11327386647462845\n",
            "epoch3, iter60, loss: 0.11498954892158508\n",
            "Finish epoch 3, time elapsed 7.96302342414856\n",
            "---------iter=0\n",
            "epoch3, pix_acc: 0.6688285827636719, meanIoU: 0.22220902575657125, IoUs: [5.57954252e-01 5.99320303e-01 0.00000000e+00 8.10828050e-01\n",
            " 7.36003245e-02 3.18597007e-01 0.00000000e+00 4.37049298e-05\n",
            " 8.39556433e-02 0.00000000e+00 0.00000000e+00]\n",
            "epoch4, iter0, loss: 0.09115830808877945\n",
            "epoch4, iter10, loss: 0.08363089710474014\n",
            "epoch4, iter20, loss: 0.09730930626392365\n",
            "epoch4, iter30, loss: 0.09408651292324066\n",
            "epoch4, iter40, loss: 0.09736648947000504\n",
            "epoch4, iter50, loss: 0.08516716212034225\n",
            "epoch4, iter60, loss: 0.09416398406028748\n",
            "Finish epoch 4, time elapsed 7.858204364776611\n",
            "---------iter=0\n",
            "epoch4, pix_acc: 0.75007080078125, meanIoU: 0.28735410031490016, IoUs: [0.8343143  0.67961751 0.         0.85620128 0.03285    0.66150538\n",
            " 0.         0.         0.09640664 0.         0.        ]\n",
            "epoch5, iter0, loss: 0.09235824644565582\n",
            "epoch5, iter10, loss: 0.09985751658678055\n",
            "epoch5, iter20, loss: 0.09247513115406036\n",
            "epoch5, iter30, loss: 0.07069208472967148\n",
            "epoch5, iter40, loss: 0.11444341391324997\n",
            "epoch5, iter50, loss: 0.07089436799287796\n",
            "epoch5, iter60, loss: 0.08697308599948883\n",
            "Finish epoch 5, time elapsed 7.847022771835327\n",
            "---------iter=0\n",
            "epoch5, pix_acc: 0.7373890686035156, meanIoU: 0.29151748581773207, IoUs: [0.85210354 0.69197483 0.         0.84863124 0.02117318 0.69368681\n",
            " 0.         0.         0.09912274 0.         0.        ]\n",
            "epoch6, iter0, loss: 0.07486923038959503\n",
            "epoch6, iter10, loss: 0.10231415182352066\n",
            "epoch6, iter20, loss: 0.10371534526348114\n",
            "epoch6, iter30, loss: 0.0931292325258255\n",
            "epoch6, iter40, loss: 0.07496052235364914\n",
            "epoch6, iter50, loss: 0.08969288319349289\n",
            "epoch6, iter60, loss: 0.07735669612884521\n",
            "Finish epoch 6, time elapsed 7.938371658325195\n",
            "---------iter=0\n",
            "epoch6, pix_acc: 0.7598277282714844, meanIoU: 0.3084523049349983, IoUs: [0.85488542 0.6967445  0.         0.81203604 0.12965519 0.76454449\n",
            " 0.         0.         0.13510971 0.         0.        ]\n",
            "epoch7, iter0, loss: 0.06688417494297028\n",
            "epoch7, iter10, loss: 0.08468855172395706\n",
            "epoch7, iter20, loss: 0.08857565373182297\n",
            "epoch7, iter30, loss: 0.08760014176368713\n",
            "epoch7, iter40, loss: 0.08565645664930344\n",
            "epoch7, iter50, loss: 0.06990266591310501\n",
            "epoch7, iter60, loss: 0.0762844905257225\n",
            "Finish epoch 7, time elapsed 7.9667205810546875\n",
            "---------iter=0\n",
            "epoch7, pix_acc: 0.7834725952148438, meanIoU: 0.34589154332903405, IoUs: [8.77712534e-01 7.23280796e-01 1.91204589e-05 8.35049823e-01\n",
            " 4.12321362e-01 7.79997490e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.76411436e-01 1.44155616e-05 0.00000000e+00]\n",
            "epoch8, iter0, loss: 0.07183992862701416\n",
            "epoch8, iter10, loss: 0.08315736800432205\n",
            "epoch8, iter20, loss: 0.07905421406030655\n",
            "epoch8, iter30, loss: 0.06970281153917313\n",
            "epoch8, iter40, loss: 0.09236092120409012\n",
            "epoch8, iter50, loss: 0.07228632271289825\n",
            "epoch8, iter60, loss: 0.07736241072416306\n",
            "Finish epoch 8, time elapsed 7.935069799423218\n",
            "---------iter=0\n",
            "epoch8, pix_acc: 0.8087544250488281, meanIoU: 0.36993336253279663, IoUs: [0.87951586 0.70811841 0.         0.86914149 0.56694106 0.79053507\n",
            " 0.         0.         0.25501509 0.         0.        ]\n",
            "epoch9, iter0, loss: 0.08065693825483322\n",
            "epoch9, iter10, loss: 0.05244262516498566\n",
            "epoch9, iter20, loss: 0.059309057891368866\n",
            "epoch9, iter30, loss: 0.07377593219280243\n",
            "epoch9, iter40, loss: 0.0874016210436821\n",
            "epoch9, iter50, loss: 0.07093971967697144\n",
            "epoch9, iter60, loss: 0.056498993188142776\n",
            "Finish epoch 9, time elapsed 8.050906896591187\n",
            "---------iter=0\n",
            "epoch9, pix_acc: 0.8206634521484375, meanIoU: 0.3788855731842862, IoUs: [0.88254421 0.69247509 0.         0.88769804 0.57199371 0.8106866\n",
            " 0.         0.         0.32083514 0.00150852 0.        ]\n",
            "epoch10, iter0, loss: 0.05143987387418747\n",
            "epoch10, iter10, loss: 0.07045219093561172\n",
            "epoch10, iter20, loss: 0.05402812361717224\n",
            "epoch10, iter30, loss: 0.04693371057510376\n",
            "epoch10, iter40, loss: 0.055879753082990646\n",
            "epoch10, iter50, loss: 0.06966864317655563\n",
            "epoch10, iter60, loss: 0.06273334473371506\n",
            "Finish epoch 10, time elapsed 7.959340810775757\n",
            "---------iter=0\n",
            "epoch10, pix_acc: 0.8123529052734375, meanIoU: 0.3698441266443275, IoUs: [8.66759877e-01 6.98887355e-01 0.00000000e+00 8.90324380e-01\n",
            " 5.56920473e-01 7.85765903e-01 1.41725085e-04 1.05419411e-05\n",
            " 2.68199369e-01 1.27576796e-03 0.00000000e+00]\n",
            "epoch11, iter0, loss: 0.07058612257242203\n",
            "epoch11, iter10, loss: 0.06541858613491058\n",
            "epoch11, iter20, loss: 0.05725985765457153\n",
            "epoch11, iter30, loss: 0.06407047063112259\n",
            "epoch11, iter40, loss: 0.07559111714363098\n",
            "epoch11, iter50, loss: 0.05415830761194229\n",
            "epoch11, iter60, loss: 0.05263349786400795\n",
            "Finish epoch 11, time elapsed 7.855913400650024\n",
            "---------iter=0\n",
            "epoch11, pix_acc: 0.8160466003417969, meanIoU: 0.37366943417691395, IoUs: [8.67892767e-01 7.03061930e-01 7.32151719e-04 8.97537945e-01\n",
            " 5.69125250e-01 7.45792579e-01 0.00000000e+00 2.08307955e-03\n",
            " 3.22541151e-01 1.59692287e-03 0.00000000e+00]\n",
            "epoch12, iter0, loss: 0.050076186656951904\n",
            "epoch12, iter10, loss: 0.058435261249542236\n",
            "epoch12, iter20, loss: 0.05744818598031998\n",
            "epoch12, iter30, loss: 0.053015343844890594\n",
            "epoch12, iter40, loss: 0.057202428579330444\n",
            "epoch12, iter50, loss: 0.0657472163438797\n",
            "epoch12, iter60, loss: 0.05863412842154503\n",
            "Finish epoch 12, time elapsed 7.81610107421875\n",
            "---------iter=0\n",
            "epoch12, pix_acc: 0.8176666259765625, meanIoU: 0.3764400448249922, IoUs: [8.85136292e-01 7.29083757e-01 1.70904500e-04 8.94031379e-01\n",
            " 6.22617993e-01 7.15204097e-01 0.00000000e+00 3.46494762e-04\n",
            " 2.93675396e-01 5.74180453e-04 0.00000000e+00]\n",
            "epoch13, iter0, loss: 0.05367153510451317\n",
            "epoch13, iter10, loss: 0.060027241706848145\n",
            "epoch13, iter20, loss: 0.07416938245296478\n",
            "epoch13, iter30, loss: 0.0518307127058506\n",
            "epoch13, iter40, loss: 0.05217677727341652\n",
            "epoch13, iter50, loss: 0.07056644558906555\n",
            "epoch13, iter60, loss: 0.07326417416334152\n",
            "Finish epoch 13, time elapsed 7.7257843017578125\n",
            "---------iter=0\n",
            "epoch13, pix_acc: 0.8288948059082031, meanIoU: 0.38762081937684556, IoUs: [8.89415477e-01 7.15050836e-01 1.00778065e-04 8.99875482e-01\n",
            " 5.88026338e-01 7.97103100e-01 4.73484848e-05 9.88503502e-03\n",
            " 3.64059873e-01 2.64746469e-04 0.00000000e+00]\n",
            "epoch14, iter0, loss: 0.045354701578617096\n",
            "epoch14, iter10, loss: 0.0409093052148819\n",
            "epoch14, iter20, loss: 0.05523102357983589\n",
            "epoch14, iter30, loss: 0.0581006184220314\n",
            "epoch14, iter40, loss: 0.059928297996520996\n",
            "epoch14, iter50, loss: 0.05942663550376892\n",
            "epoch14, iter60, loss: 0.07179903984069824\n",
            "Finish epoch 14, time elapsed 7.784805536270142\n",
            "---------iter=0\n",
            "epoch14, pix_acc: 0.8270980834960937, meanIoU: 0.3904351666179395, IoUs: [8.78583944e-01 7.20351461e-01 1.81064565e-04 9.06696024e-01\n",
            " 6.14547864e-01 7.22933482e-01 1.49031297e-05 1.77364031e-02\n",
            " 4.29147338e-01 4.59434997e-03 0.00000000e+00]\n",
            "epoch15, iter0, loss: 0.054221414029598236\n",
            "epoch15, iter10, loss: 0.05757024139165878\n",
            "epoch15, iter20, loss: 0.06493765115737915\n",
            "epoch15, iter30, loss: 0.05403292179107666\n",
            "epoch15, iter40, loss: 0.09243135899305344\n",
            "epoch15, iter50, loss: 0.05719947814941406\n",
            "epoch15, iter60, loss: 0.059174999594688416\n",
            "Finish epoch 15, time elapsed 7.764277696609497\n",
            "---------iter=0\n",
            "epoch15, pix_acc: 0.8097392272949219, meanIoU: 0.3709136942628018, IoUs: [8.65813153e-01 6.85439939e-01 3.58301315e-04 9.00873738e-01\n",
            " 6.17256117e-01 7.39605668e-01 3.98713736e-03 1.69345983e-02\n",
            " 2.49162903e-01 6.19080881e-04 0.00000000e+00]\n",
            "epoch16, iter0, loss: 0.07126644998788834\n",
            "epoch16, iter10, loss: 0.05833366885781288\n",
            "epoch16, iter20, loss: 0.04527437314391136\n",
            "epoch16, iter30, loss: 0.05287979915738106\n",
            "epoch16, iter40, loss: 0.055006243288517\n",
            "epoch16, iter50, loss: 0.04659377411007881\n",
            "epoch16, iter60, loss: 0.051030710339546204\n",
            "Finish epoch 16, time elapsed 7.729206562042236\n",
            "---------iter=0\n",
            "epoch16, pix_acc: 0.83629150390625, meanIoU: 0.40125738023894647, IoUs: [8.92001072e-01 7.43479820e-01 1.83148585e-04 9.12019169e-01\n",
            " 6.52050549e-01 7.50724891e-01 2.91888439e-05 2.01619781e-02\n",
            " 4.42994254e-01 1.87110805e-04 0.00000000e+00]\n",
            "epoch17, iter0, loss: 0.05511646717786789\n",
            "epoch17, iter10, loss: 0.04914019629359245\n",
            "epoch17, iter20, loss: 0.057651542127132416\n",
            "epoch17, iter30, loss: 0.056024979799985886\n",
            "epoch17, iter40, loss: 0.06034724414348602\n",
            "epoch17, iter50, loss: 0.04964905232191086\n",
            "epoch17, iter60, loss: 0.045292120426893234\n",
            "Finish epoch 17, time elapsed 7.764746427536011\n",
            "---------iter=0\n",
            "epoch17, pix_acc: 0.8351809692382812, meanIoU: 0.3981840987720658, IoUs: [8.84870069e-01 7.21758809e-01 1.32889508e-04 9.10418824e-01\n",
            " 7.13833710e-01 7.98829464e-01 8.81419344e-03 1.88388061e-02\n",
            " 3.21552872e-01 9.75449146e-04 0.00000000e+00]\n",
            "epoch18, iter0, loss: 0.05908644571900368\n",
            "epoch18, iter10, loss: 0.058648400008678436\n",
            "epoch18, iter20, loss: 0.05210437998175621\n",
            "epoch18, iter30, loss: 0.041947122663259506\n",
            "epoch18, iter40, loss: 0.05211133137345314\n",
            "epoch18, iter50, loss: 0.05560872331261635\n",
            "epoch18, iter60, loss: 0.0488901287317276\n",
            "Finish epoch 18, time elapsed 7.6533238887786865\n",
            "---------iter=0\n",
            "epoch18, pix_acc: 0.830806884765625, meanIoU: 0.4038200297868411, IoUs: [8.70508765e-01 7.16780537e-01 1.11946060e-04 9.00660261e-01\n",
            " 6.86435755e-01 7.51983216e-01 5.18559789e-03 1.49369090e-01\n",
            " 3.60241176e-01 7.43983874e-04 0.00000000e+00]\n",
            "epoch19, iter0, loss: 0.04376937821507454\n",
            "epoch19, iter10, loss: 0.06166427955031395\n",
            "epoch19, iter20, loss: 0.05006147921085358\n",
            "epoch19, iter30, loss: 0.047176506370306015\n",
            "epoch19, iter40, loss: 0.04747765138745308\n",
            "epoch19, iter50, loss: 0.04952167347073555\n",
            "epoch19, iter60, loss: 0.04878464341163635\n",
            "Finish epoch 19, time elapsed 7.656769514083862\n",
            "---------iter=0\n",
            "epoch19, pix_acc: 0.8356089782714844, meanIoU: 0.41727945199707206, IoUs: [8.79593686e-01 7.04383124e-01 9.59296106e-05 9.04367364e-01\n",
            " 6.27496977e-01 7.92107059e-01 1.26526484e-02 2.54656936e-01\n",
            " 4.06280811e-01 8.43569336e-03 3.74266905e-06]\n",
            "The highest mIOU is 0.41727945199707206 and is achieved at epoch-20\n",
            "The highest pixel accuracy  is 0.83629150390625 and is achieved at epoch-17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYz53spZY--Y",
        "colab_type": "text"
      },
      "source": [
        "##### Before eliminating the skip-connection (x3,x4),\n",
        "The highest mIOU is 0.423 and is achieved at epoch-17\n",
        "The highest pixel accuracy  is 0.8459 and is achieved at epoch-17\n",
        "\n",
        "##### After eliminating the skip-connection (x3,x4),\n",
        "The highest mIOU is 0.417 and is achieved at epoch-20\n",
        "The highest pixel accuracy  is 0.836 and is achieved at epoch-17\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmBAE-TMY--c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}